<!doctype html>
<html>
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
	<link rel="stylesheet" href="reveal/reset.css">
	<link rel="stylesheet" href="reveal/reveal.css">
	<link rel="stylesheet" href="reveal/theme/white.css">
	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="reveal/plugin/highlight/monokai.css">

	<style>
		p {
			font-size: 22px;
		}
	</style>

	<title>Segment Me If You Can</title>
</head>
<body>
<!---------------------------------------------------------------------->

<div class="reveal">
<div class="slides">

	<section>
		<h2>Segment Me <span style="color: red">If You Can</span></h2>

		<h3>A Benchmark for Anomaly Segmentation</h3>
	</section>

	<section>
		<h5>Meet the Team!</h5>
		<div style="display: flex; font-size: 1.2rem; justify-content: space-evenly;">
			<div>
				<div>Robin Chan</div>
				<img height="150rem" src="robin.jpeg" /><br/>
				<img width="110rem" src="buw.png" style="margin-top: 0px;"/>
			</div>
			<div>
				<div>Krzysztof Lis</div>
				<img height="150rem" src="kris.jpeg" /><br/>
				<img width="110rem" src="epfl.png" style="margin-top: 0px;" />
			</div>
			<div>
				<div>Svenja Uhlemeyer</div>
				<img height="150rem" src="svenja.jpeg" /><br/>
				<img width="110rem" src="buw.png"  style="margin-top: 0px;" />
			</div>
			<div>
				<div>Hermann Blum</div>
				<img height="150rem" src="hermann.jpeg" /><br/>
				<img width="110rem" src="ethz.png" style="margin-top: 0px;" />
			</div>
		</div>
		<div style="display: flex; font-size: 1.2rem; justify-content: space-evenly;">
			<div>
				<div>Sina Honari</div>
				<img height="150rem" src="sina.jpeg" /><br/>
				<img width="110rem" src="epfl.png" style="margin-top: 0px;"/>
			</div>
			<div>
				<div>Roland Siegwart</div>
				<img height="150rem" src="roland.jpeg" /><br/>
				<img width="110rem" src="ethz.png" style="margin-top: 0px;"/>
			</div>
			<div>
				<div>Pascal Fua</div>
				<img height="150rem" src="pascal.jpg" /><br/>
				<img width="110rem" src="epfl.png" style="margin-top: 0px;"/>
			</div>
			<div>
				<div>Mathieu Salzmann</div>
				<img height="150rem" src="mathieu.jpeg" /><br/>
				<img width="110rem" src="epfl.png" style="margin-top: 0px;"/>
			</div>
			<div>
				<div>Matthias Rottmann</div>
				<img height="150rem" src="matthias.jpeg" /><br/>
				<img width="110rem" src="buw.png" style="margin-top: 0px;"/>
			</div>
		</div>
	</section>

	<section data-background="deeplab_fail.png">
		<h5 style="margin-bottom: 60%;" >Deep CNNs are unreliable outside of their training distribution</h5>
	</section>

	<section>
		<h5>Perception Failures were at the Heart of Past Accidents</h5>
		<div style="display: flex; justify-content: center;">
			<img width="50%" src="news1.png" style="transform: translateX(5rem);" />
			<img width="50%" src="news2.png" style="transform: translateX(-5rem);" />
		</div>
	</section>

	<section>
		<h5>We benchmark semantic anomalies.</h5>
		<div style="font-size: 22px">
		<ul>
			<li>We benchmark the identification of semantic anomalies that do not fit into any class definitions.</li>
			<li>2 Tracks:
				<ul>
					<li>Anomaly Track: detect and localize anomaly  with respect to Cityscapes.</li>
					<li>Obstacle Track: detect and localize anything that is <strong>not</strong> drivable area on the road.</li>
				</ul>
			</li>
			<li>based on real-world images</li>
		</ul></div>
		<div style="font-size: 30px; margin-top: 20px;">Public leaderboard and submission instructions at <a href="https://segmentmeifyoucan.com/">segmentmeifyoucan.com</a>.</div>
	</section>

	<section>
		<h5>Data for Anomaly Segmentation is Scarce</h5>
		<img src="dataset_overview.png" />
	</section>

	<section>
		<h5>Public Leaderboard</h5>
		<iframe data-src="https://segmentmeifyoucan.com/" width="90%" height="500rem" data-preload></iframe>
	</section>

	<section>
		<h5>Datasets</h5>
		<iframe data-src="https://segmentmeifyoucan.com/datasets" width="90%" height="500rem" data-preload></iframe>
	</section>

	<section>
		<h5>RoadAnomaly21</h5>
		<div style="display: flex; justify-content: center; font-style: italic; font-size: 18px;">
		<figure>
			<img height="140px" src="images/airplane0001_blend.jpg"/>
			<img height="140px" src="images/cones0006_blend.jpg"/>
			<figcaption>Anomalies can appear everywhere in the image.</figcaption>
		</figure>
		</div>
		<div style="display: flex; justify-content: center; font-style: italic; font-size: 18px;">
		<figure>
			<img height="140px" src="images/cow0001_blend.jpg"/>
			<img height="140px" src="images/tractor0005_blend.jpg"/>
			<figcaption>Anomalies widely differ in size.</figcaption>
		</figure>
		</div>
		<div style="display: flex; justify-content: center; font-style: italic; font-size: 18px;">
		<figure>
			<img height="140px" src="images/leopard0000_blend.jpg"/>
			<img height="140px" src="images/sheep0008_blend.jpg"/>
			<figcaption>Wide variety of environments.</figcaption>
		</figure>
		</div>
	</section>

	<section>
		<h5>Labeling Policy</h5>
		<div style="font-size: 22px;">
			<p> Decision whether an object is anomalous or not is based on the 19 Cityscapes evaluation classes. If an object can be assigned to one of these classes, it is labeled as not anomaly (white), otherwise as anomaly (orange) or void (black). </p>
		</div>
		<div style="display: flex; justify-content: center; font-style: italic; font-size: 18px;">
		<figure>
			<img height="140px" src="images/carriage0002.jpg"/>
			<img height="140px" src="images/carriage0002_labels_semantic_color.png"/>
			<figcaption>The objects of interest are the carriage including the horses. The other unknown objects in the background (e.g. parasols, chair) are voided. We also void small gaps inside of the anomalies.</figcaption>
		</figure>
		</div>
	</section>

	<section>
		<h5>RoadObstacle21</h5>
		<div style="display: flex; justify-content: center; font-style: italic; font-size: 18px;">
		<figure>
			<img height="140px" src="images/greyasphalt_basket_1_blend.jpg"/>
			<img height="140px" src="images/greyasphalt_basket_7_blend.jpg"/>
			<figcaption>Obstacles appear at different distances.</figcaption>
		</figure>
		</div>
		<div style="display: flex; justify-content: center; font-style: italic; font-size: 18px;">
		<figure>
			<img height="140px" src="images/gravel_boxG_2_blend.jpg"/>
			<img height="140px" src="images/paving_watercanB_2_blend.jpg"/>
			<figcaption>Different road surfaces.</figcaption>
		</figure>
		</div>
		<div style="display: flex; justify-content: center; font-style: italic; font-size: 18px;">
		<figure>
			<img height="140px" src="images/snowstorm1_00_16_02.578_blend.jpg"/>
			<img height="140px" src="images/driveway_shovel_2_2_blend.jpg"/>
			<figcaption>Different lighting and weather conditions..</figcaption>
		</figure>
		</div>
	</section>

	<section>
		<h5>Labeling Policy</h5>
		<div style="font-size: 22px;">
			<p> The road ahead is the region of interest, labeled as not obstacle (white). Every object placed on the road is labeled as obstacle (orange), everything besides the road is voided (black). We also void areas that could distract the model, such as wet spots on the road. </p>
		</div>
		<div style="display: flex; justify-content: center; font-style: italic; font-size: 18px;">
		<figure>
			<img height="160px" src="images/gravel_boot_5.webp"/>
			<img height="160px" src="images/gravel_boot_5_labels_semantic_color.png"/>
			<figcaption>The road is the region of interest. The boot is labeled as obstacle, the background and the wet spots are ignored in the evaluation. </figcaption>
		</figure>
		</div>
	</section>

	<section>
		<h5>Anomaly Segmentation Performance Metrics</h5>
		<div style="font-size: 22px">
		<ul>
			<li>Classic pixel-wise metrics:
				<ul>
					<li>AUROC: Area under receiver operating characteristic curve (TPR vs. FPR)</li>
					<li><strong>AUPRC</strong>: Area under precision recall curve (precision vs. recall)</li>
				</ul>
			</li>
			<li>Recent component-wise metrics:
				<ul>
					<li>sIoU: adjusted component-wise intersection over union wrt ground truth</li>
					<li>PPV: component-wise positive predictive value (or precision) wrt prediction</li>
					<li>TP: sIoU greater than a given threshold &tau;</li>
					<li>FN: sIoU smaller than a given threshold &tau;</li>
					<li>FP: PPV smaller than a given threshold &tau;</li>
					<li><strong>F1(&tau;)</strong> :=  2TP / (2TP + FP + FN) &isin; [0,1] averaged over &tau;=0.25,0.30,...0.75</li>
				</ul>
			</li>
		</ul>
		</div>
		<div style="display: flex; justify-content: center; font-style: italic; font-size: 18px;">
		<figure>
			<img height="200px" src="images/elephant0006_blend_crop.jpg"/>
			<figcaption>Ordinary vs. adjusted component-wise intersection over union.
				<br><span style="color:green">green contour</span>: IoU=68.18% vs. sIoU=87.01%
				<br><span style="color:red">red contour</span>: IoU=21.68% vs. sIoU=68.44%
			</figcaption>
		</figure>
		</div>
	</section>

<section data-markdown><textarea data-template>
##### Evaluation and submission

Loaders and metrics code: [github.com/SegmentMeIfYouCan/road-anomaly-benchmark](https://github.com/SegmentMeIfYouCan/road-anomaly-benchmark)

Submit outputs for evaluation against private ground-truths.
Public validation set is available.

```python
from road_anomaly_benchmark.evaluation import Evaluation

ev = Evaluation(
    method_name = 'MyMethod',
    dataset_name = 'ObstacleTrack-all',
)

for fr in ev.get_frames():
	# run your detector with the benchmark images
    anomaly_p = my_method(fr.image)
    ev.save_result(fr, anomaly_p)

# files are being written in a background thread
ev.wait_to_finish_saving()
```
</textarea></section>

<section data-markdown><textarea data-template>

##### Reusable metrics

* Metrics can be used with other datasets
* Add new metrics in a modular way

```bash
# Pixel classification (PR, ROC) metric
python -m road_anomaly_benchmark metric PixBinaryClass \
	method1,method2 ObstacleTrack-validation

# Instance level metrics
python -m road_anomaly_benchmark metric SegEval-ObstacleTrack \
	method1,method2 dset1,dset2
```

</textarea>
</section>



<section data-markdown><textarea data-template>
<h5>Generate curves and tables</h5>

```bash
python -m road_anomaly_benchmark comparison \
	MyComparison \
	metric1,metric2 \
	method1,method2 \
	dset1,dset2
```

<figure style="width: 960px; height: 400px; position: relative;">
	<img style="position: absolute; top: 0; left: 0; border: solid black 2px;" height="300" src="images/implementation/leaderboard_anomaly.png" />
	<img style="position: absolute; bottom: 0; right: 0; border: solid black 2px;" height="400" src="images/implementation/pix_class_curves2.png" />
</figure>
<!-- <p>
	Leaderboard at <a href="https://segmentmeifyoucan.com/leaderboard">
		SegmentMeIfYouCan.com/leaderboard
	</a>
	</p> -->
</textarea>
</section>

<section data-markdown><textarea data-template>
<h5>Benchmark results - advantages:</h5>

* Tailored solutions
* Out-of-distribution training data
	
<figure style="" >
	<img style="" width="450" src="images/results/results_anomaly.png" />
	<img style="" width="450" src="images/results/results_obstacle.png" />
</figure>
</textarea></section>


</div>
</div>

<!---------------------------------------------------------------------->

<script src="reveal/reveal.js"></script>
<script src="reveal/plugin/notes/notes.js"></script>
<script src="reveal/plugin/markdown/markdown.js"></script>
<script src="reveal/plugin/highlight/highlight.js"></script>
<script>
	// More info about initialization & config:
	// - https://revealjs.com/initialization/
	// - https://revealjs.com/config/
	Reveal.initialize({
		hash: true,

		// Learn about plugins: https://revealjs.com/plugins/
		plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
	});
</script>
</body>
</html>
